# -*- coding: utf-8 -*-
"""Feature_Importance.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dnjJU98Ig2GtXCPeEjEZ7ie7wlySiy_G
"""

import pandas as pd
import numpy as np
import random

df = pd.read_csv('/content/Original_data.csv')
df.head()

df['LoanID'].nunique()

df.shape

df['LoanID'] = np.random.choice(range(255348), size=len(df), replace=False)

df.head()

df['LoanID'].nunique()

df['Education'].replace(["Bachelor's", "Master's", 'High School', 'PhD'],[1,2,0,3],inplace=True)

df['Education'].unique()

df.isnull().sum()

#df.drop('LoanID',axis=1,inplace=True)

df_ohe = pd.get_dummies(df)
df_ohe.head()

df_ohe.columns

X=df_ohe.drop('Default',axis=1)
Y=df_ohe['Default']

X.shape , Y.shape



"""# TrainTest Split"""

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=7,stratify = Y)

X_train.head()

X_train.isnull().sum()

"""# **Getting Feature importance**

# APPLY DECISION TREE
"""

from sklearn.tree import DecisionTreeClassifier

dt = DecisionTreeClassifier(random_state = 7)
dt.fit(X_train,y_train)

# importance of all features
sorted(zip(dt.feature_importances_,X_train.columns),reverse = True)

# 2) mean importance take col > mean import
mean_imp = sum(dt.feature_importances_)/len(dt.feature_importances_)
X_train.columns[dt.feature_importances_ > mean_imp ]

# 3) Select top 5
sorted(zip(dt.feature_importances_,X_train.columns),reverse = True)[:5]

"""# APPLY RFE"""

from sklearn.feature_selection import RFE

rfe = RFE(dt)
rfe.fit(X_train,y_train)

for imp,col in sorted(zip(rfe.ranking_,X_train.columns)):
    print(f"{col} = {imp}")

#2) important column rank = 1

print("Column Count = ",len(X_train.columns[rfe.ranking_ == 1  ]))
X_train.columns[rfe.ranking_ == 1 ]