# -*- coding: utf-8 -*-
"""Model_Building.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1tRxvCR2P2-j9FIqnbLDeMLDzLglfpgMF
"""

import pandas as pd
import random

df=pd.read_csv("/content/Selected_features.csv")
print(df.head())

df.shape

X=df.drop('Default',axis=1)
Y=df['Default']

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(8, 6))
sns.boxplot(x=df["Default"], y=df["LoanAmount"])
plt.title("Box Plot of Loan Amount by Class")
plt.xlabel("Class (0 = No Default, 1 = Default)")
plt.ylabel("Loan Amount")
plt.show()

"""# Correlation"""

# Compute correlation matrix
correlation_matrix = df.corr()

# Print correlation matrix
print(correlation_matrix)

"""# HeatMap"""

import seaborn as sns
import matplotlib.pyplot as plt

# Create a heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(correlation_matrix, annot=True, cmap="coolwarm", fmt=".2f")

# Show the plot
plt.title("Correlation Heatmap")
plt.show()

X = df[['Age', 'Income', 'LoanAmount', 'CreditScore','MonthsEmployed','InterestRate','DTIRatio','LoanTerm']]
Y= df['Default']

from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=7)

X_train.shape,X_test.shape,Y_train.shape,Y_test.shape

"""# **Model Training Using SVM**"""

#Entrypoint 2.x
from pyspark.sql import SparkSession
spark = SparkSession.builder.master("local").appName("Spark SQL basic example").enableHiveSupport().getOrCreate()

# On yarn:
# spark = SparkSession.builder.appName("Spark SQL basic example").enableHiveSupport().master("yarn").getOrCreate()
# specify .master("yarn")

sc = spark.sparkContext

file_path ="/content/NewData.csv"

# Create an DataFrame from file_path
df = spark.read.csv(file_path,header=True,inferSchema=True)

# Check the type of people_df
#print("The type of people_df is", type(people_df))

from pyspark.sql.functions import col
# Get the total count of records
total_count = df.count()

# Get the count of each class (0 and 1)
class_counts = df.groupBy("Default").count()

# Calculate the proportion of each class
class_proportions = class_counts.withColumn("proportion", col("count") / total_count)

# Show the result
class_proportions.show()

from pyspark.ml.classification import LinearSVC
from pyspark.ml.feature import VectorAssembler, StandardScaler
from pyspark.ml.evaluation import BinaryClassificationEvaluator
from pyspark.sql.functions import col, when
# Initialize Spark session
#spark = SparkSession.builder.appName("Loan Default Prediction").getOrCreate()

# Load dataset (assuming CSV format with header)
#df = spark.read.csv("loan_data.csv", header=True, inferSchema=True)

# Selecting features and target column
feature_cols = ['Age', 'Income', 'LoanAmount', 'CreditScore','MonthsEmployed','InterestRate','DTIRatio','LoanTerm']
target_col = 'Default'

# Assemble features into a single vector
assembler = VectorAssembler(inputCols=feature_cols, outputCol="features")
data = assembler.transform(df)

# Train-test split
train, test = data.randomSplit([0.8, 0.2], seed=13)

# Define SVM model
svm = LinearSVC(featuresCol="features", labelCol=target_col, maxIter=50, regParam=0.1)

# Train model
svm_model = svm.fit(train)

# Make predictions
predictions = svm_model.transform(test)

# Convert predictions to binary (0 or 1) to match the actual labels
predictions = predictions.withColumn("final_prediction", when(col("prediction") == 1.0, 1).otherwise(0))

# Calculate accuracy
correct_predictions = predictions.filter(col("final_prediction") == col(target_col)).count()
total_predictions = predictions.count()
accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0

# Evaluate AUC
evaluator = BinaryClassificationEvaluator(labelCol=target_col)
auc = evaluator.evaluate(predictions)

print(f"Model Accuracy: {accuracy:.2f}")
print(f"AUC: {auc:.2f}")

!pip install onnxmltools

!pip install onnxruntime

!pip install scikit-learn

!pip install skl2onnx

"""# **Storing Model into onnx file**"""

import numpy as np
from sklearn.svm import LinearSVC
import skl2onnx
from skl2onnx.convert import convert_sklearn
from skl2onnx.common.data_types import FloatTensorType

# Dummy data for training the model
X_dummy = np.zeros((2, 8))  # 2 samples, 8 features (same as Spark model)
y_dummy = np.array([0, 1])  # Labels

# Train a dummy model to initialize it
sklearn_model = LinearSVC()
sklearn_model.fit(X_dummy, y_dummy)

# Manually set coefficients from Spark's LinearSVC
sklearn_model.coef_ = svm_model.coefficients.toArray().reshape(1, -1)
sklearn_model.intercept_ = np.array([svm_model.intercept])

# Specify the initial input types for skl2onnx conversion
initial_types = [('input', FloatTensorType([None, 8]))]  # 8 features

# Convert the model to ONNX format
onnx_model = convert_sklearn(sklearn_model, initial_types=initial_types)

# Save the ONNX model
with open("svm_model.onnx", "wb") as f:
    f.write(onnx_model.SerializeToString())

# Compute confusion matrix
from pyspark.mllib.evaluation import MulticlassMetrics
from pyspark.sql.functions import col
predictionAndLabels = predictions.select(col("prediction"), col(target_col).cast("double")).rdd
metrics = MulticlassMetrics(predictionAndLabels)
confusion_matrix = metrics.confusionMatrix()
print("Confusion Matrix:\n", confusion_matrix)

# Interpret confusion matrix
true_negatives = confusion_matrix[0, 0]
false_positives = confusion_matrix[0, 1] if confusion_matrix.numCols > 1 else 0
false_negatives = confusion_matrix[1, 0] if confusion_matrix.numRows > 1 else 0
true_positives = confusion_matrix[1, 1] if confusion_matrix.numRows > 1 and confusion_matrix.numCols > 1 else 0

print(f"True Negatives: {true_negatives}")
print(f"False Positives: {false_positives}")
print(f"False Negatives: {false_negatives}")
print(f"True Positives: {true_positives}")

# Compute Precision, Recall, and F1 Score
precision_0 = metrics.precision(0.0)
recall_0 = metrics.recall(0.0)
f1_score_0 = metrics.fMeasure(0.0)

precision_1 = metrics.precision(1.0)
recall_1 = metrics.recall(1.0)
f1_score_1 = metrics.fMeasure(1.0)

print(f"Class 0 - Precision: {precision_0}, Recall: {recall_0}, F1 Score: {f1_score_0}")
print(f"Class 1 - Precision: {precision_1}, Recall: {recall_1}, F1 Score: {f1_score_1}")

